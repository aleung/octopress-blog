<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: Android | Good good study, day day up]]></title>
  <link href="http://aleung.github.com/blog/tags/android/atom.xml" rel="self"/>
  <link href="http://aleung.github.com/blog/"/>
  <updated>2012-12-12T01:05:23+08:00</updated>
  <id>http://aleung.github.com/blog/</id>
  <author>
    <name><![CDATA[Leo Liang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Android: 在應用中設定locale]]></title>
    <link href="http://aleung.github.com/blog/2012/10/06/change-locale-in-android-application/"/>
    <updated>2012-10-06T00:25:00+08:00</updated>
    <id>http://aleung.github.com/blog/2012/10/06/change-locale-in-android-application</id>
    <content type="html"><![CDATA[<p>近幾天把以前做的跑步步频训练软件 <a href="https://play.google.com/store/apps/details?id=leoliang.runningcadence">RunningCadence</a> 加上了多語言支持，可以在應用中設定界面以及語音播報所用的語言。</p>

<p>對多語言的支持，Android已經做得很完善，開發者只需要在應用中加入各種locale的資源文件。但是，應用只會使用系統全局設置的locale，而要在應用自己的設定中選擇locale，以及要讓設定立即生效，就需要開發者自己去實現了。</p>

<p>本來，一般應用並沒必要自己提供語言設定，用系統全局設定就好了。但這個 RunningCadence 使用了語音合成(TTS)功能，而一般手機上安裝的TTS引擎支持的語言都有限，如果TTS不支持系統locale的語言，那就聽不到聲音了，所以需要花力氣去搞這個應用內的語言選擇。</p>

<h2 id="localelocale">讓應用啓動時使用自己設定的locale，而非系統locale</h2>

<p>開發應用時要爲不同locale準備不同的資源，在應用中通過 <a href="http://developer.android.com/reference/android/content/res/Resources.html">Resources</a> 類來加載資源，各個界面組件的構建都需要用到資源。而具體資源如何選擇是受 <a href="http://developer.android.com/reference/android/content/res/Configuration.html">Configuration</a> 影響的，Configuration帶有設備的硬件相關配置信息（如屏幕分辨率，屏幕方向）和系統全局配置信息（如locale），由系統底層框架提供。</p>

<p>應用啓動時，Configuration中的locale會被設置爲系統locale。應用若要使用自己的locale，就必須在創建界面之前，將Resources裏的Configuration更改。</p>

<p>這個更改在application的 onCreate() 裏面做最合適，對應用全局生效，因爲它在任何activity創建之前就執行了，不再需要在各個activity裏做任何事情。</p>

<p>``` java
	@Override
	public void onCreate() {
		setLocale();
	}</p>

<pre><code>public void setLocale() {
	Locale locale = getLocaleFromPref();
	Locale.setDefault(locale);
	Configuration config = getBaseContext().getResources().getConfiguration();
	overwriteConfigurationLocale(config, locale);
}

private void overwriteConfigurationLocale(Configuration config, Locale locale) {
	config.locale = locale;
	getBaseContext().getResources()
			.updateConfiguration(config, getBaseContext().getResources().getDisplayMetrics());
} ```
</code></pre>

<p>加了這段代碼後，應用啓動時就會根據 getLocaleFromPref() 返回的語言來顯示了，但是你會發現如果將手機屏幕轉一下，例如豎屏變爲橫屏，界面又會變回系統缺省語言，爲什麼呢？</p>

<p>系統底層框架會在configuration發生了變化時通知應用<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>。對application是調用 Application.onConfigurationChanged() 方法。對activity的處理採用那種方式，就與manifest文件中&lt;Activity&gt;的 android:configChanges 屬性配置相關：</p>

<ul>
  <li>如果發生的是configChanges中指定的事件，調用 Activity.onConfigurationChanged()，不重啓activity；</li>
  <li>否則重啓activity。</li>
</ul>

<p>屏幕的旋轉就是一種 runtime change，缺省情況下會觸發activity的重啓，也就是銷毀並重新創建activity<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>，重新創建時使用的是新的Configuration，裏面帶的又是系統locale，因此就造成了界面變回系統缺省語言。</p>

<p>爲了避免這種情況，需要在Application的 onConfigurationChanged() 裏面也對Configuration做修改。</p>

<p><code>java
	@Override
	public void onConfigurationChanged(Configuration newConfig) {
		Locale locale = getLocaleFromPref();
		Locale.setDefault(locale);
		overwriteConfigurationLocale(newConfig, locale);
		super.onConfigurationChanged(newConfig);
	}
</code></p>

<p>做了這些後，應用就能使用自己的locale設定，而不是系統locale了。完整代碼例子可以參考RunningCadence源碼 <a href="https://github.com/aleung/RunningCadence/blob/c658e00bd24a23bd95369bf6e3d87254776ae2cb/RunningCadence/src/leoliang/runningcadence/Application.java">Application.java</a>。</p>

<h2 id="preferencelocale">讓應用preference中的locale設定修改立即生效</h2>

<p>應用通常會使用 Preference API 來構造用戶設定界面，在上一步完成後，用戶可以在應用preference裏設置locale，在應用重新啓動時會使用選定的locale。但是用戶在preference裏修改locale後是不會立即生效的，因爲修改沒有反映到 configuration 中去，而且對於已經存在的activity，界面組件都已經創建好了，界面上的文字不可能自動改變。</p>

<p>一種方案是讓整個應用重新啓動，所有資源都重新加載，所有界面都重新創建。我留意了一下，大部分提供應用內語言設定的應用都是這樣做的——在彈出對話框裏選擇語言並確認後，不會返回到設定頁面，而是顯示應用的入口界面——應用已經重啓了。在 RunningCadence 中，我不想用這種方法，因爲用戶體驗會不好——用戶在修改語言後，通常還要選擇另一個選項進行語音合成測試，看看TTS對新選擇的語言能否正常工作——如果應用重啓返回主界面，用戶就得再進入設定界面才能進行測試，一方面是操作麻煩了，另一方面界面無緣無故跳轉也會帶來困惑。</p>

<h3 id="configuration">在用戶修改設定後，更新Configuration</h3>

<p>更新Configuration的方法跟應用啓動時的做法一樣，可以重用 setLocale() 方法，問題是要能在合適的時機去調用。使用SharedPreference的修改通知機制可以做到這點。</p>

<p>``` java
    public class PreferenceActivity extends android.preference.PreferenceActivity implements
    		OnSharedPreferenceChangeListener {</p>

<pre><code>	// ...

	@Override
	public void onSharedPreferenceChanged(SharedPreferences sharedPreferences, String key) {
		if (key.equals("pref_language")) {
			((Application) getApplication()).setLocale();
			restartActivity();
		}
	}

	@Override
	protected void onCreate(Bundle savedInstanceState) {
		super.onCreate(savedInstanceState);
		addPreferencesFromResource(R.xml.preferences);
		getPreferenceScreen().getSharedPreferences().registerOnSharedPreferenceChangeListener(this);
	}

	@Override
	protected void onStop() {
		super.onStop();
		getPreferenceScreen().getSharedPreferences().unregisterOnSharedPreferenceChangeListener(this);
	}
} ```
</code></pre>

<p>要注意這個listener的寫法，如果按照通常Android程序風格，使用匿名內部類來實現，就會發生詭異的問題，總是不會被回調。這個問題花了我好長時間，誤打誤撞解決了也沒明白什麼回事，寫這篇文章時才看見StackOverflow上有這個問題的<a href="http://stackoverflow.com/a/3104265/94148">根源解答</a>。</p>

<h3 id="locale">將已經存在的界面按照新locale重新顯示</h3>

<p>先分析哪些activity是需要重新顯示的，這需要對應用的 <a href="http://developer.android.com/guide/components/tasks-and-back-stack.html">task stack</a> 結構有一個審視。要知道在locale更改的時刻，哪些activity還在生存着，會在後續操作中重新變爲可見狀態，這些activity的界面需要重建。在RunningCadence裏比較簡單，就是PreferenceActivity本身和調用它的主activity。</p>

<p>要讓activity的界面按新locale重新顯示，最簡單的方法應該就是讓它重啓，這比起對每個界面元件都用重新加載資源去重設要簡單得多。</p>

<p><code>java
	private void restartActivity() {
		Intent intent = getIntent();
		finish();
		startActivity(intent);
	}
</code></p>

<p>PreferenceActivity的重啓是在OnSharedPreferenceChangeListener得知設定發生了改變的時候進行，在上面的代碼例子裏已經顯示出來了。而主activity的重啓是在當用戶從PreferenceActivity中返回到主activity時，在onActivityResult() 中觸發。</p>

<p>完整代碼例子可以參考RunningCadence源碼 <a href="https://github.com/aleung/RunningCadence/blob/f0cdb98b42a94caa5c7e2cec1a8aa6abf91e73b9/RunningCadence/src/leoliang/runningcadence/PreferenceActivity.java">PreferenceActivity.java</a>。</p>

<h2 id="section">總結</h2>

<p>現在將思路理清了寫下來，感覺不算複雜，但是在做的過程中費了好多腦筋繞了不少彎路，邊上網查資料邊嘗試。Android的API Guides在ICS發佈後改進了好多，很多內容重寫過更清晰容易理解了，另外一個非常有價值的資源是<a href="StackOverflow.com">StackOverflow.com</a>。</p>

<p>我感覺，對於一般應用沒有太大必要去實現應用內的語言選擇。系統裏所有應用都使用統一的locale本來就挺好的。</p>

<p>如果應用的task stack結構複雜，需要重新顯示的activity很多，可能用重啓整個應用的方法更簡單一些。我不知道重啓應用是怎麼做到的，Android API裏面沒有現成的方法。不過若實現了應用重啓，應用內部各個Activity都不需要做任何額外處理了。</p>

<hr />

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>詳細機制見 <a href="http://developer.android.com/guide/topics/resources/runtime-changes.html">Handling Runtime Changes</a><a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>在 <a href="/2010/12/16/Android-activity-lifecycle-in-UML-state-machine-diagram">Android Activity Lifecycle in UML</a> 文中的狀態圖可以見到configChanged引發的狀態遷移。<a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Xperia U 上手]]></title>
    <link href="http://aleung.github.com/blog/2012/07/22/xperia-u/"/>
    <updated>2012-07-22T18:22:00+08:00</updated>
    <id>http://aleung.github.com/blog/2012/07/22/xperia-u</id>
    <content type="html"><![CDATA[<p><img src="/attachments/2012/7/xperia-u.png"></p>

<p><a href="http://en.wikipedia.org/wiki/Nexus_One">Nexus One</a> 手机用了两年多，升过几次系统，到现在用起来还是挺满意，但唯一的问题是内部存储(ROM)太小了，只有512M，留给安装应用的空间不足200M，而现在的应用又越来越大，已经到了当想装新应用必须先卸载其他一些的地步了。尝试过A2SD，效果不大理想，卡顿感比较明显，也可能因为我的TF卡速度不够高。</p>

<p>现在换的这个 <a href="http://www.sonymobile.com/global-en/products/phones/xperia-u/">Sony Xperia U</a> 属于 <a href="http://www.xperiablog.net/2012/03/07/xperia-nxt-specifications-compared-%E2%80%93-xperia-p-vs-xperia-s-vs-xperia-u/">Xperia NXT</a> 系列，称为Sony下一代智能手机，包括 Xperia S, Xperia P 和 Xperia U，档次由高至低。Xperia U 在配置上其实跟 Nexus One 变化不算大（<a href="http://geekaphone.com/compare/Sony-Xperia-U-vs-HTC-Nexus-One">对比</a>），主要区别是CPU双核(频率相同)，内部存储容量4G，而其他的如屏幕之类都不相上下。不过，两个产品发布时间差了2年，Nexus One在当年算是旗舰级别，而现在Xperia U只是中端机型，在现在的手机大混战中一点都不起眼。这也正符合我目前的需要，相当于一个内存升级版的Nexus One。之前考虑过人称Google三儿子的Galaxy Nexus，样样都满意，不过有些特性我倒用不着，例如4.6寸大屏幕。</p>

<p>玩了几天，跟我的期望比较一致，总体满意。有些经验记录下来。</p>

<h2 id="section">刷机</h2>

<p>参考前一篇 <a href="/2012/07/21/flashing-xperia-u/">Xperia U 刷机</a>。</p>

<h2 id="section-1">透明发光条</h2>

<p>在屏幕下方软按键处有一条称为 illuminating transparent band 的发光条，晚上环境光线暗的时候，那条光带有点刺眼，干脆不要亮好了，找到一个应用 <a href="https://play.google.com/store/apps/details?id=com.haxor">Screen Filter</a> 可以将soft-key backlight关闭。另外，在 Google Play 搜索“illumination bar”可以找到一些应用能够将这个发光条用作未接来电、未读短信、邮件的提醒灯。</p>

<h2 id="usb">USB连接电脑</h2>

<p>Xperia NXT 系列的USB连接采用<a href="http://en.wikipedia.org/wiki/Media_Transfer_Protocol">MTP</a> (Media Transfer Protocol) 模式，而不是通常的MSC(Mass Storage)模式。在Windows里，USB连上后，会显示成一个没有盘符的设备，可以在explorer中访问，但在Mac OS X中，就根本看不到。XDA上有人做了个应用<a href="http://forum.xda-developers.com/showthread.php?t=1606940">SDCARD Mounter</a>，装在手机上后（需要root），能够将Xperia S/U/P的内部存储空间用MSC模式mount起来，这样在电脑上就能够像U盘一样访问了。</p>

<p>如果手机没有root，那么Mac OS X还可以安装<a href="http://www.android.com/filetransfer/">Android File Transfer</a>来访问手机存储，不过我没有试过是否可行。重要的是，Android File Transfer只能在它的窗口中看到手机的文件，而不是挂载在文件系统上，在finder和shell中都访问不了，这是因为MTP模式下文件系统并不是由电脑端管理，而是在设备端管理。我需要用script来控制传输文件，因此只能用MSC模式。</p>

<h2 id="dlna">DLNA</h2>

<p>用Xperia自带应用播放音乐、视频或者浏览照片时，菜单里有一个选项叫做”Play on device”，说明是 find &amp; connect to DLNA device。</p>

<p>DLNA是什么呢，上网查了一通，原来这是一个类似Apple的AirPlay的规范，通过网络在设备之间共享数字媒体播放。准确的说，<a href="http://en.wikipedia.org/wiki/Digital_Living_Network_Alliance">DLNA</a>的功能集比AirPlay要广很多，定义了 media server，media player，media renderer，media controller 等多种设备（实际上一种设备可以身兼多职），现在应用广泛的有两种模式：</p>

<ul>
  <li>
    <p><strong>播放媒体服务器上的音频视频（pull）</strong>。在一个设备(media player)上，浏览和播放另外一台设备(media server)上的资源。这时，用户是在播放设备上进行操作的，例如在手机上播放电脑里保存的视频。</p>
  </li>
  <li>
    <p><strong>将媒体推送到另外一个设备远程播放（push）</strong>。如将在手机上正在看的视频推送到大电视上播放，这时手机是media controller，电视机是media renderer，media server看情况，可能是手机也可能是其他设备，要看媒体源在哪里。跟另一种模式的区别是，用户并不是在播放设备上进行操作的，手上的设备就像一个遥控器。这也是AirPlay能做的事情。</p>
  </li>
</ul>

<p>Xperia U 的 play on device 就是push模式。但我家里没有支持DLNA的电视机，有没有办法推送到电脑，用电脑的显示器来播放呢？如果是Win7就很好办，Win7带的Media Player内置支持DLNA，将媒体库菜单里的“允许远程控制我的播放器”选中就可以了。但是我的电脑用的是Mac OS X，这种办法走不通。后来发现大名鼎鼎的<a href="http://xbmc.org/">XBMC</a>也支持 DLNA renderer 功能，在network setting里面将 Allow control of XBMC via UPnP 选上，手机 play on device 菜单里果然就出现了XBMC可供选择。另外，还惊喜的发现 XBMC 还有 Allow XBMC to receive AirPlay content 选项，测试过能够将iPad的视频推送到XBMC中播放。太好了，那就可以用 Thunderbolt Display 来看了。</p>

<p>Xperia U 还可以充当 DLNA media server，试过在电脑上用<a href="http://www.videolan.org/vlc/">VLC</a>可以浏览手机上的所有视频、音乐、照片。需要在手机的 Connected devices 应用中enable。</p>

<h3 id="reference">Reference:</h3>

<ul>
  <li><a href="/2010/05/11/Nexus-One-/">Nexus One 到手，以及刷机过程</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Xperia U 刷机]]></title>
    <link href="http://aleung.github.com/blog/2012/07/21/flashing-xperia-u/"/>
    <updated>2012-07-21T23:20:00+08:00</updated>
    <id>http://aleung.github.com/blog/2012/07/21/flashing-xperia-u</id>
    <content type="html"><![CDATA[<p>昨天中午拿到国行 <a href="http://www.sonymobile.com/global-en/products/phones/xperia-u/">Sony Xperia U</a> (ST25i) 手机，开机试了一下，索尼(原来的索尼爱立信)在Android 2.3基础上的定制系统做得还可以，但大陆行货里好多功能都被阉割得不成样子。Google系列的任何东西都去掉了就不用说了，很奇怪的是居然系统里没有自带任何应用市场，国内的山寨市场也没有。可以想象一个不熟悉IT的用户买到手机后就会局限在预装的那几个应用，连升级都没有途径。比较一下SonyMobile英文与中文网站对这款手机的介绍，就会发现中文产品介绍缩水不少，好多卖点都没有了。</p>

<p>这样的智能手机简直就是残废，于是下班后就开始研究怎么刷机。先是在国内的一些论坛上搜索，但国内论坛真是很没有营养，里面的信息的价值很低。Android hacker的大本营在XDA，相关问题还是要到<a href="http://www.xda-developers.com/">XDA论坛</a>找靠谱。</p>

<p>关于Xperia系列刷机需要了解的基础知识，这篇 <a href="http://forum.xda-developers.com/showthread.php?t=1526866">All that u need to know before u begin</a> 讲得比较清楚。</p>

<p>无论要刷什么，前提条件是先将 bootloader 解锁。关于解锁的教程很多，SonyMobile网站上就有详细步骤，XDA上的 <a href="http://forum.xda-developers.com/showthread.php?t=1527159">Xperia S/P/U/Sola Bootloader Unlocking &amp; Relocking</a> 附带了所需工具的下载。还有一个国产软件，号称是一键自动解锁。</p>

<p>但是，就在第一步，将手机boot到fastboot模式，就花了我好几个小时。按教程，手机在关机状态按着音量+键的同时将USB连接上电脑，就会进入fastboot模式，并且亮起蓝灯。但是无论我怎么反复重试，手机都不会亮起蓝灯，电脑上弹出对话框提示安装驱动程序，但当我选择操作时它又说USB设备已经断开，显示这样的错误信息：s1boot fastboot device unplugged。网上搜索，有人说是驱动没有装好的原因，最后还是从XDA里找到了<a href="http://forum.xda-developers.com/showthread.php?t=1554632">解决方案</a>。原来，Xperia手机在进入fastboot模式时，会检测电脑是否已经装上了正确的驱动程序，如果没有，就会退出fastboot模式。而电脑端刚刚提示用户安装驱动，就发现手机已经关闭了连接，就取消了驱动的安装。这种问题可以用来做经典反面案例了。XDA帖子里的解决方法还是要拼手快：预先打开设备管理器，一插上手机后，里面会出现s1boot这个设备，赶紧鼠标右键选择升级驱动，升级驱动的对话框打开后，即使设备断开了还是可以继续进行驱动程序的安装。终于看到传说中的蓝灯了，原来是在下面透明发光条发出很亮的蓝光，我之前还一直以为是右上角摄像头旁边的小灯。</p>

<p>接下来就非常顺利了，解锁bootloader后，用fastboot安装了ROM和Kernel。我都没有另外用其他工具了，感觉fastboot用起来就很简单，很多人不喜欢可能是因为命令行操作吧。关于fastboot使用，推荐看cyanogenmod的wiki里的<a href="http://wiki.cyanogenmod.com/wiki/Fastboot">介绍</a>。</p>

<p>我刷的ROM是<a href="http://forum.xda-developers.com/showthread.php?t=1684062">KA02 Xperia SSpeed</a>， 还是Android 2.3.7，Sony还没有为Xperia U 提供Android 4.0 ICS。Kernel是<a href="http://forum.xda-developers.com/showthread.php?t=1688147">Advanced Stock Kernel</a>。刷完开机，见到熟悉Google账号绑定，然后Gmail、通信录、日历同步、Google Play都回来了。Root也有了，收工。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[跑步步频训练软件 RunningCadence 开发小记]]></title>
    <link href="http://aleung.github.com/blog/2011/12/24/Running-training-software-development-XiaoJi-RunningCadence-step-frequency/"/>
    <updated>2011-12-24T00:16:00+08:00</updated>
    <id>http://aleung.github.com/blog/2011/12/24/Running-training-software-development-XiaoJi-RunningCadence-step-frequency</id>
    <content type="html"><![CDATA[<p>在<a href="http://good-good-study.appspot.com/blog/posts/156002">10km跑总结</a>里提到：这次10km跑成绩的提高最重要因素是步频的提高。</p>

<p>在网上看了一些资料，提到提高步频的好处，并指出长跑理想的步频应该在每分钟180步左右，就开始尝试练习提高步频。但是跑起来并不知道怎样的频率才是合适的，还需要有工具测量才行。想到可以用手机的加速度传感器来测量，跑步时把手机绑在手臂上或者拿手上，测量手的摆动周期应该就可以计算出步频。</p>

<p>有了想法后，就考虑怎样实现。先要知道跑步时加速度传感器得到的数据会是怎样的，在market上找到软件Accelero-meter Log，能显出加速度传感器三轴数据的曲线。拿着手机跑了几步看看曲线，发现完全不是想象中那么简单：从曲线可以看出每跑一步的加速度变化，但并不是一步一个脉冲那么理想，而是大脉冲中包含着小脉冲，波形很不规则；更要命的是不同轴测量到的数据频率会不一样，软件应该按那个轴的数据计算？后来才想到不同轴测量数据频率不同的原因是手摆动的频率与身体重心上下移动的频率不一致，只是一半，再加上手的活动太自如了，跑动过程中会有不同的动作，都会引起加速度变化。</p>

<p>上网找到一个开源的Android计步器的代码，看看它怎么做，发现它只是将三个轴的数值加在一起，然后判断变化量。根据前面看得的数据波形，我感觉这样的算法太不靠谱了，再看看这个软件的用户评价，果然不佳。</p>

<p>这时想到Nike的配合iPhone使用的计步器，是藏在鞋里面的。它应该是感应脚的每次着地，而且计步器是固定在鞋里的，有特定的安装方向，因此它可以只检测垂直地面的加速度。想到这里就豁然开朗了，原来测量摆臂的想法是错误的，应该测量脚着地的冲击，也就是垂直方向的加速度。但那个轴才是垂直地面的呢？我不能规定用户使用这个软件时手机摆放的方向啊，他可以绑在臂上，拿在手里，放裤袋中。。。因此首先要解决的问题是如何判断手机的姿态，找出垂直于地面的轴。</p>

<p>人在运动的时候加速度不断变化，但加速度矢量一段时间的累计应该为零，而重力加速度是恒定的，并且垂直于地面，检测出重力加速度的方向就ok了。具体实现的方法也比较简单：对传感器三个轴的数据分别做截止频率为0.25Hz的低通滤波后，数值最大的那个轴应该就是最接近于垂直地面的。</p>

<p>还有个问题是手机加速度传感器的采样频率能到多高？是否能满足要求？长跑理想的着地次数是每分钟180次，相当于3Hz，一般人都只会比这个慢。实测我的Nexus One使用最短采样间隔时大约30~50ms能获取到一组数据，也就是采样频率大于20Hz，对于检测3Hz的信号完全足够。</p>

<p>对于复杂波形的处理方法，同样是简单的一阶低通滤波，截止频率取了3.5Hz，相当于每分钟210次着地。高频干扰通过滤波削弱后，相邻波峰的时间间隔就是两次着地的时间间隔了。具体实现时，波峰判断会比较麻烦，采样检查是否超过阈值来代替。本来想按振幅比例来设定阈值的，但算振幅也比较麻烦，之前检测重力加速度时已经得到重力加速度在测量轴上的分量，直接拿它的1/2做阈值就好了。这样做还带来了一个没有预料到的副作用：走路时脚步比较轻，超不过阈值，因此软件还能知道当前是否处于跑步状态。</p>

<p>步频数据算出来以后其他的就好办了。跑步时不方便看屏幕，通过语音合成播放出来。设定目标步频，语音提示应该加快还是减慢。还打算过增加个目标步频的节拍音，当实际步频与目标不一致时播放出来，不过软件用了这段时间，感觉有语音播报步频基本上已经足够了，暂时不做以后再说吧。</p>

<p>这个软件项目的网站： <a href="http://code.google.com/p/running-cadence/">http://code.google.com/p/running-cadence/</a></p>

<p>软件发布在Android Market:<a href="https://market.android.com/details?id=leoliang.runningcadence">https://market.android.com/details?id=leoliang.runningcadence</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Drag and drop list view on Android]]></title>
    <link href="http://aleung.github.com/blog/2011/04/10/Drag-and-drop-list-view-on-Android/"/>
    <updated>2011-04-10T06:05:00+08:00</updated>
    <id>http://aleung.github.com/blog/2011/04/10/Drag-and-drop-list-view-on-Android</id>
    <content type="html"><![CDATA[<p>I didn’t expect that implementing a drag and drop list view on Android is so difficult. It took me more than one week to get it work.</p>

<p>Android SDK doesn’t provide too much support on drag and drop, at least there is no out of box API that can be used till Android 3.0 Honeycomb. It’s said that drag and drop support is improved in Android 3.0 SDK, I didn’t learn it yet because Android 3.0 hasn’t come to mobile device.</p>

<p>At first I looked for open source implementation of drag and drop list view. After searching on Internet I did find some examples and library, e.g. <a href="https://github.com/commonsguy/cwac-touchlist">CWAC TouchListView</a> , they all derives from source code of Android music application. However they don’t fit for my application: First, they require to specify the height of item view in code or in layout file, that also implicitly force all item views in the same height. In my application the list view has two item view types, which differ in height. Even if item views are in same height, I don’t like the way that specifying exact value of height, I perfer to set <code>layout_height</code> to <code>wrap_content</code> and let it automatically calculates the value. Second, by those implementation, on each list item view there must be a “grabber” element. User moves an item by putting finger on the grabber then drag. I want to keep UI of my application as clean as it can, I would like to active item dragging by long press on an item, instead of drag a grabber. So I implement my version of drag and drop list view, the source code is at GitHub: <a href="https://github.com/aleung/tasks365/blob/master/tasks365/src/leoliang/tasks365/DraggableListView.java">DraggableListView</a>. It isn’t perfect yet, still has large room for improvement.</p>

<p>A ListView shows items in a vertically scrolling list. The items can be refered by their position in the list. When there are a lot of items, only portion of them are visible. A visible item view can be retrieved by calling <code>ListView.getChildAt()</code>. Please be noticed that child view index is different to item position. In the code you will find these two values need to be converted between each other.</p>

<p><a href="http://www.flickr.com/photos/leoliang/5603506949/"><img src="http://farm6.static.flickr.com/5267/5603506949_627d31073c.jpg" alt="listview" /></a></p>

<p>Long press on an item is detected by<code>GestureDetector</code>, then a dragging object is created. The dragging object represents on UI by an ImageView, which is a copy of the view of the item to be moved. The dragging object moves on screen following user’s finger. Untill user’s finger leave touch screen, the list items do not change their order, they just expand or shrink to simulate item dragging.</p>

<p>In below diagram, dragging object is in green. Item at position 3 is being dragged in this example. When dragging starts, the view of item 3 shrinks its height to 1 to make it invisible (I didn’t investigate why height should be 1 instead of 0). User sees item 3 is dragged, actually it’s the dragging object – clone of the item 3 view. When dragging object is hovering at a position, the item view at that position expands to make an empty space, so looks like that it is being pushed aside by the dragging object.</p>

<p><a href="http://www.flickr.com/photos/leoliang/5604090272/"><img src="http://farm6.static.flickr.com/5101/5604090272_641594fa57_m.jpg" alt="listview-dnp-1" /></a><a href="http://www.flickr.com/photos/leoliang/5603507715/"><img src="http://farm6.static.flickr.com/5188/5603507715_d47cb49532_m.jpg" alt="listview-dnp-2" /></a></p>

<p>Here is a screenshot of demo:</p>

<p><a href="http://www.flickr.com/photos/leoliang/5603811095/"><img src="http://farm5.static.flickr.com/4099/5603811095_f2f7c52c79.jpg" alt="DraggableListView" /></a></p>
]]></content>
  </entry>
  
</feed>
